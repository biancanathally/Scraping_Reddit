# Reddit Scraper ğŸğŸ¤–

Este projeto Ã© um web scraper automatizado desenvolvido em Python para extrair tÃ³picos e discussÃµes relevantes de subreddits especÃ­ficos. Ele identifica palavras-chave relacionadas ao desenvolvimento e organiza os dados em formatos estruturados para anÃ¡lise posterior.

## ğŸš€ Funcionalidades

* **ExtraÃ§Ã£o seletiva**: Filtra tÃ­tulos de posts baseados em palavras-chave.
* **MÃºltiplos formatos de saÃ­da**: Salva os dados automaticamente em `JSON` (para persistÃªncia de objetos) e `CSV` (para anÃ¡lise em planilhas ou Data Science).
* **Tratamento de erros**: Sistema robusto para lidar com falhas de conexÃ£o ou mudanÃ§as na estrutura do HTML.
* **GestÃ£o de caminhos**: Utiliza a biblioteca `pathlib` para garantir que os arquivos sejam salvos corretamente em qualquer sistema operacional (macOS, Windows ou Linux).

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.x**
* **Requests**: Para realizar requisiÃ§Ãµes HTTP de forma eficiente.
* **BeautifulSoup4**: Para o parsing e extraÃ§Ã£o de dados do HTML.
* **Pathlib**: Para manipulaÃ§Ã£o inteligente de diretÃ³rios.

## ğŸ“‹ PrÃ©-requisitos

Antes de rodar o script, vocÃª precisarÃ¡ instalar as dependÃªncias:

```bash
pip install requests beautifulsoup4
```

## ğŸ”§ Como Usar

1. Clone este repositÃ³rio ou baixe o arquivo `main.py`.
2. Abra o terminal na pasta do projeto.
3. Execute o script:

```bash
python3 main.py
```

Os arquivos `python_topics.json` e `python_topics.csv` serÃ£o gerados automaticamente na mesma pasta do script.

## ğŸ“Š Estrutura dos Dados

O scraper organiza as informaÃ§Ãµes da seguinte forma:

* **Subreddit**: Origem do dado.
* **Type**: Categoria (se Ã© um tÃ³pico principal ou uma discussÃ£o/comentÃ¡rio).
* **Title**: O texto extraÃ­do do post.
* **URL**: Link direto para a discussÃ£o (quando disponÃ­vel).
* **Scraped_at**: Timestamp exato da coleta.

## âš ï¸ Notas legais e Ã©ticas

Este projeto foi desenvolvido para fins acadÃªmicos e de estudo (Mestrado). Ao utilizÃ¡-lo, respeite os [Termos de ServiÃ§o do Reddit](https://www.redditinc.com/policies/data-api-terms) e utilize intervalos de tempo entre as requisiÃ§Ãµes (`time.sleep`) para evitar sobrecarga nos servidores.
